\begin{thebibliography}{11}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Cheng et~al.(2020)Cheng, Li, Wu, Meng, Xu, and Ngan]{Cheng2020LearnTP}
Qishang Cheng, Hongliang Li, Q.~Wu, Fanman Meng, Linfeng Xu, and K.~Ngan.
\newblock Learn to pay attention via switchable attention for image
  recognition.
\newblock \emph{2020 IEEE Conference on Multimedia Information Processing and
  Retrieval (MIPR)}, pp.\  291--296, 2020.

\bibitem[Han et~al.(2015)Han, Mao, and Dally]{Han2015DeepCC}
Song Han, Huizi Mao, and W.~Dally.
\newblock Deep compression: Compressing deep neural network with pruning,
  trained quantization and huffman coding.
\newblock \emph{arXiv: Computer Vision and Pattern Recognition}, 2015.

\bibitem[He et~al.(2015)He, Zhang, Ren, and Sun]{He2015DelvingDI}
Kaiming He, X.~Zhang, Shaoqing Ren, and Jian Sun.
\newblock Delving deep into rectifiers: Surpassing human-level performance on
  imagenet classification.
\newblock \emph{2015 IEEE International Conference on Computer Vision (ICCV)},
  pp.\  1026--1034, 2015.

\bibitem[Howard et~al.(2017)Howard, Zhu, Chen, Kalenichenko, Wang, Weyand,
  Andreetto, and Adam]{Howard2017MobileNetsEC}
Andrew~G. Howard, Menglong Zhu, Bo~Chen, Dmitry Kalenichenko, Weijun Wang,
  Tobias Weyand, M.~Andreetto, and Hartwig Adam.
\newblock Mobilenets: Efficient convolutional neural networks for mobile vision
  applications.
\newblock \emph{ArXiv}, abs/1704.04861, 2017.

\bibitem[Iandola et~al.(2016)Iandola, Moskewicz, Ashraf, Han, Dally, and
  Keutzer]{Iandola2016SqueezeNetAA}
F.~Iandola, Matthew~W. Moskewicz, Khalid Ashraf, Song Han, W.~Dally, and
  K.~Keutzer.
\newblock Squeezenet: Alexnet-level accuracy with 50x fewer parameters and <1mb
  model size.
\newblock \emph{ArXiv}, abs/1602.07360, 2016.

\bibitem[Jaderberg et~al.(2015)Jaderberg, Simonyan, Zisserman, and
  Kavukcuoglu]{Jaderberg2015SpatialTN}
Max Jaderberg, K.~Simonyan, Andrew Zisserman, and K.~Kavukcuoglu.
\newblock Spatial transformer networks.
\newblock \emph{ArXiv}, abs/1506.02025, 2015.

\bibitem[Sandler et~al.(2018)Sandler, Howard, Zhu, Zhmoginov, and
  Chen]{Sandler2018MobileNetV2IR}
M.~Sandler, Andrew~G. Howard, Menglong Zhu, A.~Zhmoginov, and Liang-Chieh Chen.
\newblock Mobilenetv2: Inverted residuals and linear bottlenecks.
\newblock \emph{2018 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, pp.\  4510--4520, 2018.

\bibitem[Tan \& Le(2019)Tan and Le]{Tan2019EfficientNetRM}
Mingxing Tan and Quoc~V. Le.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks.
\newblock \emph{ArXiv}, abs/1905.11946, 2019.

\bibitem[Wang et~al.(2018)Wang, Peng, and Liu]{wang2018mask}
Yangang Wang, Cong Peng, and Yebin Liu.
\newblock Mask-pose cascaded cnn for 2d hand pose estimation from single color
  image.
\newblock \emph{IEEE Transactions on Circuits and Systems for Video
  Technology}, 29\penalty0 (11):\penalty0 3258--3268, 2018.

\bibitem[Xu et~al.(2015)Xu, Ba, Kiros, Cho, Courville, Salakhutdinov, Zemel,
  and Bengio]{Xu2015ShowAA}
Ke~Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron~C. Courville,
  R.~Salakhutdinov, R.~Zemel, and Yoshua Bengio.
\newblock Show, attend and tell: Neural image caption generation with visual
  attention.
\newblock pp.\  2048--2057, 2015.

\bibitem[Zhang et~al.(2017)Zhang, Zhou, Lin, and Sun]{Zhang2017ShuffleNetAE}
Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, and Jian Sun.
\newblock Shufflenet: An extremely efficient convolutional neural network for
  mobile devices.
\newblock \emph{2018 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, pp.\  6848--6856, 2017.

\end{thebibliography}
