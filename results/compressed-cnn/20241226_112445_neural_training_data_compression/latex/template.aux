\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Kaplan2020ScalingLF,Tang2020CommunicationEfficientDD}
\citation{azimi2020structural}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\newlabel{sec:intro@cref}{{[section][1][]1}{[1][1][]1}}
\citation{wang2022learning}
\citation{azimi2020structural}
\citation{Chen2019LossyID}
\citation{Tishby2015DeepLA}
\citation{wang2022learning}
\citation{Hu2024ASO}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}\protected@file@percent }
\newlabel{sec:related}{{2}{2}{Related Work}{section.2}{}}
\newlabel{sec:related@cref}{{[section][2][]2}{[1][2][]2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Background}{2}{section.3}\protected@file@percent }
\newlabel{sec:background}{{3}{2}{Background}{section.3}{}}
\newlabel{sec:background@cref}{{[section][3][]3}{[1][2][]2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Problem Setting}{3}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Method}{3}{section.4}\protected@file@percent }
\newlabel{sec:method}{{4}{3}{Method}{section.4}{}}
\newlabel{sec:method@cref}{{[section][4][]4}{[1][3][]3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Frequency-Domain Compression}{3}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Distance-Preserving Projection}{3}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Spatial Structure Preservation}{4}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Binary Feature Extraction}{4}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Neural Architecture}{4}{subsection.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Experimental Setup}{4}{section.5}\protected@file@percent }
\newlabel{sec:experimental}{{5}{4}{Experimental Setup}{section.5}{}}
\newlabel{sec:experimental@cref}{{[section][5][]5}{[1][4][]4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Implementation}{4}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Training Protocol}{4}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Evaluation}{5}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Results}{5}{section.6}\protected@file@percent }
\newlabel{sec:results}{{6}{5}{Results}{section.6}{}}
\newlabel{sec:results@cref}{{[section][6][]6}{[1][5][]5}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Performance comparison across compression methods. All methods achieve 3.125:1 dimensionality reduction. Binary Thresholding achieves additional 8x storage reduction through 1-bit quantization.\relax }}{5}{table.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:results}{{1}{5}{Performance comparison across compression methods. All methods achieve 3.125:1 dimensionality reduction. Binary Thresholding achieves additional 8x storage reduction through 1-bit quantization.\relax }{table.caption.1}{}}
\newlabel{tab:results@cref}{{[table][1][]1}{[1][5][]5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Compression Performance}{5}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Training Dynamics}{5}{subsection.6.2}\protected@file@percent }
\newlabel{fig:train-loss}{{1a}{6}{Training Loss\relax }{figure.caption.2}{}}
\newlabel{fig:train-loss@cref}{{[subfigure][1][1]1a}{[1][5][]6}}
\newlabel{sub@fig:train-loss}{{a}{6}{Training Loss\relax }{figure.caption.2}{}}
\newlabel{sub@fig:train-loss@cref}{{[subfigure][1][1]1a}{[1][5][]6}}
\newlabel{fig:val-loss}{{1b}{6}{Validation Loss\relax }{figure.caption.2}{}}
\newlabel{fig:val-loss@cref}{{[subfigure][2][1]1b}{[1][5][]6}}
\newlabel{sub@fig:val-loss}{{b}{6}{Validation Loss\relax }{figure.caption.2}{}}
\newlabel{sub@fig:val-loss@cref}{{[subfigure][2][1]1b}{[1][5][]6}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Training dynamics across compression methods. Spatial methods show faster convergence and better final performance.\relax }}{6}{figure.caption.2}\protected@file@percent }
\newlabel{fig:training}{{1}{6}{Training dynamics across compression methods. Spatial methods show faster convergence and better final performance.\relax }{figure.caption.2}{}}
\newlabel{fig:training@cref}{{[figure][1][]1}{[1][5][]6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Computational Efficiency}{6}{subsection.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Limitations}{6}{subsection.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusions and Future Work}{6}{section.7}\protected@file@percent }
\newlabel{sec:conclusion}{{7}{6}{Conclusions and Future Work}{section.7}{}}
\newlabel{sec:conclusion@cref}{{[section][7][]7}{[1][6][]6}}
\bibstyle{iclr2024_conference}
\bibdata{references}
\bibcite{azimi2020structural}{{1}{2020}{{Azimi \& Pekcan}}{{Azimi and Pekcan}}}
\bibcite{Chen2019LossyID}{{2}{2019}{{Chen et~al.}}{{Chen, Fan, Wang, yu~Duan, Lin, and Kot}}}
\bibcite{Hu2024ASO}{{3}{2024}{{Hu et~al.}}{{Hu, Lou, Yan, and Ye}}}
\bibcite{Kaplan2020ScalingLF}{{4}{2020}{{Kaplan et~al.}}{{Kaplan, McCandlish, Henighan, Brown, Chess, Child, Gray, Radford, Wu, and Amodei}}}
\bibcite{Tang2020CommunicationEfficientDD}{{5}{2020}{{Tang et~al.}}{{Tang, Shi, Chu, Wang, and Li}}}
\bibcite{Tishby2015DeepLA}{{6}{2015}{{Tishby \& Zaslavsky}}{{Tishby and Zaslavsky}}}
\bibcite{wang2022learning}{{7}{2022}{{Wang et~al.}}{{Wang, Qin, and Chen}}}
\ttl@finishall
