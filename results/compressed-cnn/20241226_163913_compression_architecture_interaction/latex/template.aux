\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Han2015DeepCC}
\citation{wang2022learning}
\citation{Howard2017MobileNetsEC}
\citation{azimi2020structural}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\newlabel{sec:intro@cref}{{[section][1][]1}{[1][1][]1}}
\citation{Howard2017MobileNetsEC}
\citation{Zoph2016NeuralAS}
\citation{Han2015DeepCC}
\citation{wang2022learning}
\citation{azimi2020structural}
\citation{wang2022learning}
\citation{azimi2020structural}
\citation{Zeng2021IterativeDM}
\citation{Shi2023TECOAU}
\citation{Howard2017MobileNetsEC}
\citation{wang2022learning}
\citation{azimi2020structural}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}\protected@file@percent }
\newlabel{sec:related}{{2}{2}{Related Work}{section.2}{}}
\newlabel{sec:related@cref}{{[section][2][]2}{[1][2][]2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Background}{2}{section.3}\protected@file@percent }
\newlabel{sec:background}{{3}{2}{Background}{section.3}{}}
\newlabel{sec:background@cref}{{[section][3][]3}{[1][2][]2}}
\citation{LeCun1989OptimalBD,Han2015LearningBW}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Problem Setting}{3}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Method}{3}{section.4}\protected@file@percent }
\newlabel{sec:method}{{4}{3}{Method}{section.4}{}}
\newlabel{sec:method@cref}{{[section][4][]4}{[1][3][]3}}
\citation{wang2022learning}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experimental Setup}{4}{section.5}\protected@file@percent }
\newlabel{sec:experimental}{{5}{4}{Experimental Setup}{section.5}{}}
\newlabel{sec:experimental@cref}{{[section][5][]5}{[1][3][]4}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Results}{4}{section.6}\protected@file@percent }
\newlabel{sec:results}{{6}{4}{Results}{section.6}{}}
\newlabel{sec:results@cref}{{[section][6][]6}{[1][4][]4}}
\bibstyle{iclr2024_conference}
\bibdata{references}
\bibcite{azimi2020structural}{{1}{2020}{{Azimi \& Pekcan}}{{Azimi and Pekcan}}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:train-loss}{{1a}{5}{Training loss trajectories showing unstable learning with extreme compression ($\alpha =0.5$, $\beta =0.1$).\relax }{figure.caption.1}{}}
\newlabel{fig:train-loss@cref}{{[subfigure][1][1]1a}{[1][4][]5}}
\newlabel{sub@fig:train-loss}{{a}{5}{Training loss trajectories showing unstable learning with extreme compression ($\alpha =0.5$, $\beta =0.1$).\relax }{figure.caption.1}{}}
\newlabel{sub@fig:train-loss@cref}{{[subfigure][1][1]1a}{[1][4][]5}}
\newlabel{fig:val-loss}{{1b}{5}{Validation loss curves demonstrating superior generalization with $\alpha =0.5$, $\beta =0.5$.\relax }{figure.caption.1}{}}
\newlabel{fig:val-loss@cref}{{[subfigure][2][1]1b}{[1][4][]5}}
\newlabel{sub@fig:val-loss}{{b}{5}{Validation loss curves demonstrating superior generalization with $\alpha =0.5$, $\beta =0.5$.\relax }{figure.caption.1}{}}
\newlabel{sub@fig:val-loss@cref}{{[subfigure][2][1]1b}{[1][4][]5}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Loss curves across configurations. Shaded regions show standard error over 5 seeds.\relax }}{5}{figure.caption.1}\protected@file@percent }
\newlabel{fig:loss-curves}{{1}{5}{Loss curves across configurations. Shaded regions show standard error over 5 seeds.\relax }{figure.caption.1}{}}
\newlabel{fig:loss-curves@cref}{{[figure][1][]1}{[1][4][]5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Test accuracy comparison. Error bars indicate standard error over 5 seeds.\relax }}{5}{figure.caption.2}\protected@file@percent }
\newlabel{fig:test-accuracy}{{2}{5}{Test accuracy comparison. Error bars indicate standard error over 5 seeds.\relax }{figure.caption.2}{}}
\newlabel{fig:test-accuracy@cref}{{[figure][2][]2}{[1][4][]5}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusions and Future Work}{5}{section.7}\protected@file@percent }
\newlabel{sec:conclusion}{{7}{5}{Conclusions and Future Work}{section.7}{}}
\newlabel{sec:conclusion@cref}{{[section][7][]7}{[1][4][]5}}
\bibcite{Han2015DeepCC}{{2}{2015{a}}{{Han et~al.}}{{Han, Mao, and Dally}}}
\bibcite{Han2015LearningBW}{{3}{2015{b}}{{Han et~al.}}{{Han, Pool, Tran, and Dally}}}
\bibcite{Howard2017MobileNetsEC}{{4}{2017}{{Howard et~al.}}{{Howard, Zhu, Chen, Kalenichenko, Wang, Weyand, Andreetto, and Adam}}}
\bibcite{LeCun1989OptimalBD}{{5}{1989}{{LeCun et~al.}}{{LeCun, Denker, and Solla}}}
\bibcite{Shi2023TECOAU}{{6}{2023}{{Shi et~al.}}{{Shi, Wang, Cao, Lin, and Wang}}}
\bibcite{wang2022learning}{{7}{2022}{{Wang et~al.}}{{Wang, Qin, and Chen}}}
\bibcite{Zeng2021IterativeDM}{{8}{2021}{{Zeng et~al.}}{{Zeng, Liu, Sun, Li, Fang, and Lu}}}
\bibcite{Zoph2016NeuralAS}{{9}{2016}{{Zoph \& Le}}{{Zoph and Le}}}
\ttl@finishall
